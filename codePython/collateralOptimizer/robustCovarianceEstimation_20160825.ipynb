{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix shrinkage analysis (covariance matrix)\n",
    "\n",
    "### Objective is to explore and develope a method for dealing with large $N$ matrices, such as those encountered in portfolio optimization. Keeping in mind that the typical covariance matrix contains some N(N-1)/2 values\n",
    "#### ->> Use matrix shrinkage for covariance estimation (SKLEARN)\n",
    "```\n",
    "from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance\n",
    "```\n",
    "\n",
    "#### ->> Idea: Empirical covariance matrix good predictor for true covariance matrix. In accordance with the MLE estimator of the population covariance matrix, but poor estimator of eigen values! Thus introduce shrinkage penalty, such that the covariance eigen values, $\\{ \\lambda_1, \\dots, \\lambda_N \\}$, are scaled in a way which minimizes the ratio between largest and smallest eigen values\n",
    "\n",
    "#### ->> From Ledoit & Wolf (2015) Spectrum Estimation ...\n",
    "#### The authors acknowledge that there are numerous approaches to estimating covariance matrices that incl. the empircal covar matrix, which provides an unbiased estimator for the true covar matrix. An approach based on the linear shrinkage estimator i.e. Ledoit & Wolf (2004) and the non-linear methods as proposed by the same authors (2012).\n",
    "\n",
    "#### ->> We choose to implement the linear shrinkage approach, detailed in Ledoit & Wolf (2004), as it provides a well founded starting point for the analysis which is to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Alway run this block first! \n",
    "%matplotlib inline\n",
    "# coding=utf-8\n",
    "\n",
    "import sys\n",
    "sys.path.extend(['/Users/Dim/Desktop/school_folder/masters_thesis/gitCodeRepo/codePython/collateralOptimizer/'])\n",
    "from dataPreProcess import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.covariance import LedoitWolf, empirical_covariance\n",
    "\n",
    "# Python 3 style division operator w/o the need to convert to float\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import data from .csv\n",
    "df = pd.read_csv('/Users/Dim/Desktop/school_folder/masters_thesis/gitCodeRepo/data/noStaleX_returnsData_20160825.csv', sep=';')\n",
    "df.index = df.date\n",
    "df = df.drop('date', axis=1)\n",
    "\n",
    "# Estimate covariance using LedoitWolf, first create instance of object\n",
    "lw = LedoitWolf(assume_centered=True)\n",
    "lwFitted = lw.fit(X=df).covariance_\n",
    "\n",
    "# Estimate covariance using Empirical/MLE \n",
    "mleFitted = empirical_covariance(X=df, assume_centered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE Method\n",
      "True\n",
      "LW Method\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Test for definiteness of the covariance matrix, as suggested by TOBAM paper\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "print \"MLE Method\"\n",
    "print is_pos_def(mleFitted)\n",
    "\n",
    "print \"LW Method\"\n",
    "print is_pos_def(lwFitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test portfolio variance for different estimation procedures\n",
    "# Suppose pVar = w'Sw\n",
    "N = df.shape[1]\n",
    "w = [1/N] * N\n",
    "w = np.asarray(w)\n",
    "pVarMLE = np.dot((np.dot(np.transpose(w), mleFitted)), w)\n",
    "pVarLW  = np.dot((np.dot(np.transpose(w), lwFitted)), w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011339943392707333"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pVarMLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.7997861138801709e-05"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pVarLW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "#### ->> The L&W method produces smaller portfolio variance than the empirical/MLE method for the constrained sample (i.e. w/o stale time-series). It it well documented and is readily useable in Python\n",
    "\n",
    "#### ->> It is proposed that we continue with it's use throughout the entirety of the estimation procedure \n",
    "\n",
    "#### ->> For further empirical proof: http://scikit-learn.org/stable/auto_examples/covariance/plot_covariance_estimation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
